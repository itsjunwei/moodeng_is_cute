GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\pytorch_lightning\trainer\connectors\logger_connector\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
`Trainer(overfit_batches=1)` was configured so 1 batch will be used.
You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loading `train_dataloader` to estimate number of stepping batches.
C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:251: You requested to overfit but enabled train dataloader shuffling. We are turning off the train dataloader shuffling for you.
C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.
C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\pytorch_lightning\loops\fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  | Name             | Type       | Params | Mode
--------------------------------------------------------
0 | mel              | Sequential | 0      | train
1 | mel_augment      | Sequential | 0      | train
2 | model            | Network    | 185 K  | train
3 | device_embedding | Embedding  | 288    | train
4 | classifier       | Sequential | 6.8 K  | train
--------------------------------------------------------
192 K     Trainable params
0         Non-trainable params
192 K     Total params
0.771     Total estimated model params size (MB)
138       Modules in train mode
0         Modules in eval mode
C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.
Epoch 0:   0%|                                                                                                                                                       | 0/1 [00:00<?, ?it/s]Gradients after backward pass:
model.in_c.0.0.weight: grad mean = 0.0005526791210286319
model.in_c.0.1.weight: grad mean = 0.0001948947028722614
model.in_c.0.1.bias: grad mean = 0.0001399749016854912
model.in_c.1.0.weight: grad mean = 0.00011106351303169504
model.in_c.1.1.weight: grad mean = 6.462780584115535e-05
model.in_c.1.1.bias: grad mean = 6.0912672779522836e-05
model.stages.s1.b1.block.0.0.weight: grad mean = 3.742281114682555e-05
model.stages.s1.b1.block.0.1.weight: grad mean = 6.847041333912784e-08
model.stages.s1.b1.block.0.1.bias: grad mean = 2.7856589440489188e-05
model.stages.s1.b1.block.1.0.weight: grad mean = 0.00019043911015614867
model.stages.s1.b1.block.1.1.weight: grad mean = 2.7831410989165306e-05
model.stages.s1.b1.block.1.1.bias: grad mean = 2.106690953951329e-05
model.stages.s1.b1.block.2.0.weight: grad mean = 1.9295135643915273e-05
model.stages.s1.b1.block.2.1.weight: grad mean = 2.9671389711438678e-05
model.stages.s1.b1.block.2.1.bias: grad mean = 3.3592124964343384e-05
model.stages.s1.b2.block.0.0.weight: grad mean = 2.5076315068872645e-05
model.stages.s1.b2.block.0.1.weight: grad mean = 3.941362791692882e-08
model.stages.s1.b2.block.0.1.bias: grad mean = 1.5144745702855289e-05
model.stages.s1.b2.block.1.0.weight: grad mean = 0.00012113787670386955
model.stages.s1.b2.block.1.1.weight: grad mean = 1.9206367142032832e-05
model.stages.s1.b2.block.1.1.bias: grad mean = 1.4287238627730403e-05
model.stages.s1.b2.block.2.0.weight: grad mean = 1.2761299331032205e-05
model.stages.s1.b2.block.2.1.weight: grad mean = 2.5931385607691482e-05
model.stages.s1.b2.block.2.1.bias: grad mean = 1.7808348275138997e-05
model.stages.s1.b3.block.0.0.weight: grad mean = 2.202351242885925e-05
model.stages.s1.b3.block.0.1.weight: grad mean = 2.7228637122789223e-08
model.stages.s1.b3.block.0.1.bias: grad mean = 1.4632872080255765e-05
model.stages.s1.b3.block.1.0.weight: grad mean = 0.00011614364484557882
model.stages.s1.b3.block.1.1.weight: grad mean = 1.948666977114044e-05
model.stages.s1.b3.block.1.1.bias: grad mean = 1.3215976650826633e-05
model.stages.s1.b3.block.2.0.weight: grad mean = 1.2658724699576851e-05
model.stages.s1.b3.block.2.1.weight: grad mean = 2.5161671146634035e-05
model.stages.s1.b3.block.2.1.bias: grad mean = 1.2445540050975978e-05
model.stages.s2.b4.block.0.0.weight: grad mean = 2.2840569727122784e-05
model.stages.s2.b4.block.0.1.weight: grad mean = 3.33991465595318e-08
model.stages.s2.b4.block.0.1.bias: grad mean = 1.1893816918018274e-05
model.stages.s2.b4.block.1.0.weight: grad mean = 0.00012923074245918542
model.stages.s2.b4.block.1.1.weight: grad mean = 2.138830859621521e-05
model.stages.s2.b4.block.1.1.bias: grad mean = 1.4441296116274316e-05
model.stages.s2.b4.block.2.0.weight: grad mean = 1.1571470167837106e-05
model.stages.s2.b4.block.2.1.weight: grad mean = 2.505109841877129e-05
model.stages.s2.b4.block.2.1.bias: grad mean = 1.482749757997226e-05
model.stages.s2.b5.block.0.0.weight: grad mean = 1.0389802810095716e-05
model.stages.s2.b5.block.0.1.weight: grad mean = 2.7147986969566773e-08
model.stages.s2.b5.block.0.1.bias: grad mean = 6.224977369129192e-06
model.stages.s2.b5.block.1.0.weight: grad mean = 8.051499025896192e-05
model.stages.s2.b5.block.1.1.weight: grad mean = 1.0228127393929753e-05
model.stages.s2.b5.block.1.1.bias: grad mean = 5.739015250583179e-06
model.stages.s2.b5.block.2.0.weight: grad mean = 7.127332992240554e-06
model.stages.s2.b5.block.2.1.weight: grad mean = 1.5123539924388751e-05
model.stages.s2.b5.block.2.1.bias: grad mean = 6.6509492171462625e-06
model.stages.s3.b6.block.0.0.weight: grad mean = 1.4420287698158063e-05
model.stages.s3.b6.block.0.1.weight: grad mean = 4.879521853240476e-08
model.stages.s3.b6.block.0.1.bias: grad mean = 8.895506653061602e-06
model.stages.s3.b6.block.1.0.weight: grad mean = 0.00012525873898994178
model.stages.s3.b6.block.1.1.weight: grad mean = 1.8005732272285968e-05
model.stages.s3.b6.block.1.1.bias: grad mean = 8.865004019753542e-06
model.stages.s3.b6.block.2.0.weight: grad mean = 1.3274127013573889e-05
model.stages.s3.b6.block.2.1.weight: grad mean = 3.6238830944057554e-05
model.stages.s3.b6.block.2.1.bias: grad mean = 1.3955900612927508e-05
model.feature_extractor.0.weight: grad mean = 2.2000396711518988e-05
model.feature_extractor.1.weight: grad mean = 1.5663972590118647e-05
model.feature_extractor.1.bias: grad mean = 0.0005558758275583386
model.device_embedding.weight: grad mean = 6.068620859878138e-05
model.classifier.0.weight: grad mean = 0.00024416710948571563
model.classifier.0.bias: grad mean = 0.004014754667878151
model.classifier.2.weight: grad mean = 0.003921077586710453
model.classifier.2.bias: grad mean = 0.17992925643920898
Epoch 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  0.41it/s, v_num=2]
Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.83it/s]
C:\Users\fenel\Documents\dcase2024_task1_baseline\helpers\utils.py:13: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\ReduceOps.cpp:1808.)
model.in_c.0.0.weight: grad mean = 0.000780855945777148
model.in_c.0.1.weight: grad mean = 0.00013998632493894547
model.in_c.0.1.bias: grad mean = 0.00016160262748599052
model.in_c.1.0.weight: grad mean = 0.00010666513117030263
model.in_c.1.1.weight: grad mean = 5.9144287661183625e-05
model.in_c.1.1.bias: grad mean = 6.412295624613762e-05
model.stages.s1.b1.block.0.0.weight: grad mean = 3.722663677763194e-05
model.stages.s1.b1.block.0.1.weight: grad mean = 5.8256272694734434e-08
model.stages.s1.b1.block.0.1.bias: grad mean = 2.6414145395392552e-05
model.stages.s1.b1.block.1.0.weight: grad mean = 0.00020092324120923877
model.stages.s1.b1.block.1.1.weight: grad mean = 2.6858087949221954e-05
model.stages.s1.b1.block.1.1.bias: grad mean = 2.204735210398212e-05
model.stages.s1.b1.block.2.0.weight: grad mean = 1.9879371393471956e-05
model.stages.s1.b1.block.2.1.weight: grad mean = 3.2407584512839094e-05
model.stages.s1.b1.block.2.1.bias: grad mean = 2.3064147171680816e-05
model.stages.s1.b2.block.0.0.weight: grad mean = 2.5158551579806954e-05
model.stages.s1.b2.block.0.1.weight: grad mean = 3.314448093760802e-08
model.stages.s1.b2.block.0.1.bias: grad mean = 1.528239226900041e-05
model.stages.s1.b2.block.1.0.weight: grad mean = 0.00011360536882421002
model.stages.s1.b2.block.1.1.weight: grad mean = 1.942624840012286e-05
model.stages.s1.b2.block.1.1.bias: grad mean = 1.4735314834979363e-05
model.stages.s1.b2.block.2.0.weight: grad mean = 1.2415683158906177e-05
model.stages.s1.b2.block.2.1.weight: grad mean = 2.7644187866826542e-05
model.stages.s1.b2.block.2.1.bias: grad mean = 1.7724993085721508e-05
model.stages.s1.b3.block.0.0.weight: grad mean = 2.2243235434871167e-05
model.stages.s1.b3.block.0.1.weight: grad mean = 2.283017686011135e-08
model.stages.s1.b3.block.0.1.bias: grad mean = 1.535612864245195e-05
model.stages.s1.b3.block.1.0.weight: grad mean = 0.00011902680125785992
model.stages.s1.b3.block.1.1.weight: grad mean = 1.642265669943299e-05
model.stages.s1.b3.block.1.1.bias: grad mean = 1.3333518836589064e-05
model.stages.s1.b3.block.2.0.weight: grad mean = 1.1696945875883102e-05
model.stages.s1.b3.block.2.1.weight: grad mean = 2.0012983441120014e-05
model.stages.s1.b3.block.2.1.bias: grad mean = 1.2377257917250972e-05
model.stages.s2.b4.block.0.0.weight: grad mean = 2.0974790459149517e-05
model.stages.s2.b4.block.0.1.weight: grad mean = 2.991695779996917e-08
model.stages.s2.b4.block.0.1.bias: grad mean = 1.084299037756864e-05
model.stages.s2.b4.block.1.0.weight: grad mean = 0.00011174497194588184
model.stages.s2.b4.block.1.1.weight: grad mean = 1.8770671886159107e-05
model.stages.s2.b4.block.1.1.bias: grad mean = 1.085796429833863e-05
model.stages.s2.b4.block.2.0.weight: grad mean = 1.0885504707403015e-05
model.stages.s2.b4.block.2.1.weight: grad mean = 1.9324739696457982e-05
model.stages.s2.b4.block.2.1.bias: grad mean = 1.0736433068814222e-05
model.stages.s2.b5.block.0.0.weight: grad mean = 1.0208063940808643e-05
model.stages.s2.b5.block.0.1.weight: grad mean = 2.463944781538885e-08
model.stages.s2.b5.block.0.1.bias: grad mean = 5.35267781742732e-06
model.stages.s2.b5.block.1.0.weight: grad mean = 7.245911547215655e-05
model.stages.s2.b5.block.1.1.weight: grad mean = 9.891288755170535e-06
model.stages.s2.b5.block.1.1.bias: grad mean = 5.465490175993182e-06
model.stages.s2.b5.block.2.0.weight: grad mean = 6.564954219356878e-06
model.stages.s2.b5.block.2.1.weight: grad mean = 1.3581837265519425e-05
model.stages.s2.b5.block.2.1.bias: grad mean = 5.732716999773402e-06
model.stages.s3.b6.block.0.0.weight: grad mean = 1.331523890257813e-05
model.stages.s3.b6.block.0.1.weight: grad mean = 4.8681496167546356e-08
model.stages.s3.b6.block.0.1.bias: grad mean = 8.22445781523129e-06
model.stages.s3.b6.block.1.0.weight: grad mean = 0.0001165389476227574
model.stages.s3.b6.block.1.1.weight: grad mean = 1.730815893097315e-05
model.stages.s3.b6.block.1.1.bias: grad mean = 8.227539183280896e-06
model.stages.s3.b6.block.2.0.weight: grad mean = 1.2232936569489539e-05
model.stages.s3.b6.block.2.1.weight: grad mean = 3.323294731671922e-05
model.stages.s3.b6.block.2.1.bias: grad mean = 1.2721685379801784e-05
model.feature_extractor.0.weight: grad mean = 2.1097472199471667e-05
model.feature_extractor.1.weight: grad mean = 1.4978353647165932e-05
model.feature_extractor.1.bias: grad mean = 0.0005559887504205108
model.device_embedding.weight: grad mean = 6.079954619053751e-05
model.classifier.0.weight: grad mean = 0.00023802528448868543
model.classifier.0.bias: grad mean = 0.004018545150756836
model.classifier.2.weight: grad mean = 0.0038768888916820288
model.classifier.2.bias: grad mean = 0.1799275130033493
Epoch 2:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s, v_num=2]NaN detected before log in mel_forward
NaN detected after log in mel_forward
Loss is NaN! Check inputs and model outputs.
NaN detected before log in mel_forward
NaN detected after log in mel_forward
mel_spec stats: nan nan nan
y_hat stats: nan nan nan
Gradients after backward pass:
model.in_c.0.0.weight: grad mean = nan
model.in_c.0.1.weight: grad mean = nan
model.in_c.0.1.bias: grad mean = nan
model.in_c.1.0.weight: grad mean = nan
model.in_c.1.1.weight: grad mean = nan
model.in_c.1.1.bias: grad mean = nan
model.stages.s1.b1.block.0.0.weight: grad mean = nan
model.stages.s1.b1.block.0.1.weight: grad mean = nan
model.stages.s1.b1.block.0.1.bias: grad mean = nan
model.stages.s1.b1.block.1.0.weight: grad mean = nan
model.stages.s1.b1.block.1.1.weight: grad mean = nan
model.stages.s1.b1.block.1.1.bias: grad mean = nan
model.stages.s1.b1.block.2.0.weight: grad mean = nan
model.stages.s1.b1.block.2.1.weight: grad mean = nan
model.stages.s1.b1.block.2.1.bias: grad mean = nan
model.stages.s1.b2.block.0.0.weight: grad mean = nan
model.stages.s1.b2.block.0.1.weight: grad mean = nan
model.stages.s1.b2.block.0.1.bias: grad mean = nan
model.stages.s1.b2.block.1.0.weight: grad mean = nan
model.stages.s1.b2.block.1.1.weight: grad mean = nan
model.stages.s1.b2.block.1.1.bias: grad mean = nan
model.stages.s1.b2.block.2.0.weight: grad mean = nan
model.stages.s1.b2.block.2.1.weight: grad mean = nan
model.stages.s1.b2.block.2.1.bias: grad mean = nan
model.stages.s1.b3.block.0.0.weight: grad mean = nan
model.stages.s1.b3.block.0.1.weight: grad mean = nan
model.stages.s1.b3.block.0.1.bias: grad mean = nan
model.stages.s1.b3.block.1.0.weight: grad mean = nan
model.stages.s1.b3.block.1.1.weight: grad mean = nan
model.stages.s1.b3.block.1.1.bias: grad mean = nan
model.stages.s1.b3.block.2.0.weight: grad mean = nan
model.stages.s1.b3.block.2.1.weight: grad mean = nan
model.stages.s1.b3.block.2.1.bias: grad mean = nan
model.stages.s2.b4.block.0.0.weight: grad mean = nan
model.stages.s2.b4.block.0.1.weight: grad mean = nan
model.stages.s2.b4.block.0.1.bias: grad mean = nan
model.stages.s2.b4.block.1.0.weight: grad mean = nan
model.stages.s2.b4.block.1.1.weight: grad mean = nan
model.stages.s2.b4.block.1.1.bias: grad mean = nan
model.stages.s2.b4.block.2.0.weight: grad mean = nan
model.stages.s2.b4.block.2.1.weight: grad mean = nan
model.stages.s2.b4.block.2.1.bias: grad mean = nan
model.stages.s2.b5.block.0.0.weight: grad mean = nan
model.stages.s2.b5.block.0.1.weight: grad mean = nan
model.stages.s2.b5.block.0.1.bias: grad mean = nan
model.stages.s2.b5.block.1.0.weight: grad mean = nan
model.stages.s2.b5.block.1.1.weight: grad mean = nan
model.stages.s2.b5.block.1.1.bias: grad mean = nan
model.stages.s2.b5.block.2.0.weight: grad mean = nan
model.stages.s2.b5.block.2.1.weight: grad mean = nan
model.stages.s2.b5.block.2.1.bias: grad mean = nan
model.stages.s3.b6.block.0.0.weight: grad mean = nan
model.stages.s3.b6.block.0.1.weight: grad mean = nan
model.stages.s3.b6.block.0.1.bias: grad mean = nan
model.stages.s3.b6.block.1.0.weight: grad mean = nan
model.stages.s3.b6.block.1.1.weight: grad mean = nan
model.stages.s3.b6.block.1.1.bias: grad mean = nan
model.stages.s3.b6.block.2.0.weight: grad mean = nan
model.stages.s3.b6.block.2.1.weight: grad mean = nan
model.stages.s3.b6.block.2.1.bias: grad mean = nan
model.feature_extractor.0.weight: grad mean = nan
model.feature_extractor.1.weight: grad mean = nan
model.feature_extractor.1.bias: grad mean = nan
model.device_embedding.weight: grad mean = nan
model.classifier.0.weight: grad mean = nan
model.classifier.0.bias: grad mean = nan
model.classifier.2.weight: grad mean = nan
model.classifier.2.bias: grad mean = nan
Epoch 3:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s, v_num=2]Loss is NaN! Check inputs and model outputs.
mel_spec stats: -11.512925148010254 10.622122764587402 -1.4735697507858276
y_hat stats: nan nan nan
Gradients after backward pass:
model.in_c.0.0.weight: grad mean = nan
model.in_c.0.1.weight: grad mean = nan
model.in_c.0.1.bias: grad mean = nan
model.in_c.1.0.weight: grad mean = nan
model.in_c.1.1.weight: grad mean = nan
model.in_c.1.1.bias: grad mean = nan
model.stages.s1.b1.block.0.0.weight: grad mean = nan
model.stages.s1.b1.block.0.1.weight: grad mean = nan
model.stages.s1.b1.block.0.1.bias: grad mean = nan
model.stages.s1.b1.block.1.0.weight: grad mean = nan
model.stages.s1.b1.block.1.1.weight: grad mean = nan
model.stages.s1.b1.block.1.1.bias: grad mean = nan
model.stages.s1.b1.block.2.0.weight: grad mean = nan
model.stages.s1.b1.block.2.1.weight: grad mean = nan
model.stages.s1.b1.block.2.1.bias: grad mean = nan
model.stages.s1.b2.block.0.0.weight: grad mean = nan
model.stages.s1.b2.block.0.1.weight: grad mean = nan
model.stages.s1.b2.block.0.1.bias: grad mean = nan
model.stages.s1.b2.block.1.0.weight: grad mean = nan
model.stages.s1.b2.block.1.1.weight: grad mean = nan
model.stages.s1.b2.block.1.1.bias: grad mean = nan
model.stages.s1.b2.block.2.0.weight: grad mean = nan
model.stages.s1.b2.block.2.1.weight: grad mean = nan
model.stages.s1.b2.block.2.1.bias: grad mean = nan
model.stages.s1.b3.block.0.0.weight: grad mean = nan
model.stages.s1.b3.block.0.1.weight: grad mean = nan
model.stages.s1.b3.block.0.1.bias: grad mean = nan
model.stages.s1.b3.block.1.0.weight: grad mean = nan
model.stages.s1.b3.block.1.1.weight: grad mean = nan
model.stages.s1.b3.block.1.1.bias: grad mean = nan
model.stages.s1.b3.block.2.0.weight: grad mean = nan
model.stages.s1.b3.block.2.1.weight: grad mean = nan
model.stages.s1.b3.block.2.1.bias: grad mean = nan
model.stages.s2.b4.block.0.0.weight: grad mean = nan
model.stages.s2.b4.block.0.1.weight: grad mean = nan
model.stages.s2.b4.block.0.1.bias: grad mean = nan
model.stages.s2.b4.block.1.0.weight: grad mean = nan
model.stages.s2.b4.block.1.1.weight: grad mean = nan
model.stages.s2.b4.block.1.1.bias: grad mean = nan
model.stages.s2.b4.block.2.0.weight: grad mean = nan
model.stages.s2.b4.block.2.1.weight: grad mean = nan
model.stages.s2.b4.block.2.1.bias: grad mean = nan
model.stages.s2.b5.block.0.0.weight: grad mean = nan
model.stages.s2.b5.block.0.1.weight: grad mean = nan
model.stages.s2.b5.block.0.1.bias: grad mean = nan
model.stages.s2.b5.block.1.0.weight: grad mean = nan
model.stages.s2.b5.block.1.1.weight: grad mean = nan
model.stages.s2.b5.block.1.1.bias: grad mean = nan
model.stages.s2.b5.block.2.0.weight: grad mean = nan
model.stages.s2.b5.block.2.1.weight: grad mean = nan
model.stages.s2.b5.block.2.1.bias: grad mean = nan
model.stages.s3.b6.block.0.0.weight: grad mean = nan
model.stages.s3.b6.block.0.1.weight: grad mean = nan
model.stages.s3.b6.block.0.1.bias: grad mean = nan
model.stages.s3.b6.block.1.0.weight: grad mean = nan
model.stages.s3.b6.block.1.1.weight: grad mean = nan
model.stages.s3.b6.block.1.1.bias: grad mean = nan
model.stages.s3.b6.block.2.0.weight: grad mean = nan
model.stages.s3.b6.block.2.1.weight: grad mean = nan
model.stages.s3.b6.block.2.1.bias: grad mean = nan
model.feature_extractor.0.weight: grad mean = nan
model.feature_extractor.1.weight: grad mean = nan
model.feature_extractor.1.bias: grad mean = nan
model.device_embedding.weight: grad mean = nan
model.classifier.0.weight: grad mean = nan
model.classifier.0.bias: grad mean = nan
model.classifier.2.weight: grad mean = nan
model.classifier.2.bias: grad mean = nan
Epoch 4:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s, v_num=2]NaN detected before log in mel_forward
NaN detected after log in mel_forward
Loss is NaN! Check inputs and model outputs.
NaN detected before log in mel_forward
NaN detected after log in mel_forward
mel_spec stats: nan nan nan
y_hat stats: nan nan nan
Gradients after backward pass:
model.in_c.0.0.weight: grad mean = nan
model.in_c.0.1.weight: grad mean = nan
model.in_c.0.1.bias: grad mean = nan
model.in_c.1.0.weight: grad mean = nan
model.in_c.1.1.weight: grad mean = nan
model.in_c.1.1.bias: grad mean = nan
model.stages.s1.b1.block.0.0.weight: grad mean = nan
model.stages.s1.b1.block.0.1.weight: grad mean = nan
model.stages.s1.b1.block.0.1.bias: grad mean = nan
model.stages.s1.b1.block.1.0.weight: grad mean = nan
model.stages.s1.b1.block.1.1.weight: grad mean = nan
model.stages.s1.b1.block.1.1.bias: grad mean = nan
model.stages.s1.b1.block.2.0.weight: grad mean = nan
model.stages.s1.b1.block.2.1.weight: grad mean = nan
model.stages.s1.b1.block.2.1.bias: grad mean = nan
model.stages.s1.b2.block.0.0.weight: grad mean = nan
model.stages.s1.b2.block.0.1.weight: grad mean = nan
model.stages.s1.b2.block.0.1.bias: grad mean = nan
model.stages.s1.b2.block.1.0.weight: grad mean = nan
model.stages.s1.b2.block.1.1.weight: grad mean = nan
model.stages.s1.b2.block.1.1.bias: grad mean = nan
model.stages.s1.b2.block.2.0.weight: grad mean = nan
model.stages.s1.b2.block.2.1.weight: grad mean = nan
model.stages.s1.b2.block.2.1.bias: grad mean = nan
model.stages.s1.b3.block.0.0.weight: grad mean = nan
model.stages.s1.b3.block.0.1.weight: grad mean = nan
model.stages.s1.b3.block.0.1.bias: grad mean = nan
model.stages.s1.b3.block.1.0.weight: grad mean = nan
model.stages.s1.b3.block.1.1.weight: grad mean = nan
model.stages.s1.b3.block.1.1.bias: grad mean = nan
model.stages.s1.b3.block.2.0.weight: grad mean = nan
model.stages.s1.b3.block.2.1.weight: grad mean = nan
model.stages.s1.b3.block.2.1.bias: grad mean = nan
model.stages.s2.b4.block.0.0.weight: grad mean = nan
model.stages.s2.b4.block.0.1.weight: grad mean = nan
model.stages.s2.b4.block.0.1.bias: grad mean = nan
model.stages.s2.b4.block.1.0.weight: grad mean = nan
model.stages.s2.b4.block.1.1.weight: grad mean = nan
model.stages.s2.b4.block.1.1.bias: grad mean = nan
model.stages.s2.b4.block.2.0.weight: grad mean = nan
model.stages.s2.b4.block.2.1.weight: grad mean = nan
model.stages.s2.b4.block.2.1.bias: grad mean = nan
model.stages.s2.b5.block.0.0.weight: grad mean = nan
model.stages.s2.b5.block.0.1.weight: grad mean = nan
model.stages.s2.b5.block.0.1.bias: grad mean = nan
model.stages.s2.b5.block.1.0.weight: grad mean = nan
model.stages.s2.b5.block.1.1.weight: grad mean = nan
model.stages.s2.b5.block.1.1.bias: grad mean = nan
model.stages.s2.b5.block.2.0.weight: grad mean = nan
model.stages.s2.b5.block.2.1.weight: grad mean = nan
model.stages.s2.b5.block.2.1.bias: grad mean = nan
model.stages.s3.b6.block.0.0.weight: grad mean = nan
model.stages.s3.b6.block.0.1.weight: grad mean = nan
model.stages.s3.b6.block.0.1.bias: grad mean = nan
model.stages.s3.b6.block.1.0.weight: grad mean = nan
model.stages.s3.b6.block.1.1.weight: grad mean = nan
model.stages.s3.b6.block.1.1.bias: grad mean = nan
model.stages.s3.b6.block.2.0.weight: grad mean = nan
model.stages.s3.b6.block.2.1.weight: grad mean = nan
model.stages.s3.b6.block.2.1.bias: grad mean = nan
model.feature_extractor.0.weight: grad mean = nan
model.feature_extractor.1.weight: grad mean = nan
model.feature_extractor.1.bias: grad mean = nan
model.device_embedding.weight: grad mean = nan
model.classifier.0.weight: grad mean = nan
model.classifier.0.bias: grad mean = nan
model.classifier.2.weight: grad mean = nan
model.classifier.2.bias: grad mean = nan
Epoch 5:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s, v_num=2]Loss is NaN! Check inputs and model outputs.
mel_spec stats: -11.512925148010254 10.647062301635742 -1.4514050483703613
y_hat stats: nan nan nan
Gradients after backward pass:
model.in_c.0.0.weight: grad mean = nan
model.in_c.0.1.weight: grad mean = nan
model.in_c.0.1.bias: grad mean = nan
model.in_c.1.0.weight: grad mean = nan
model.in_c.1.1.weight: grad mean = nan
model.in_c.1.1.bias: grad mean = nan
model.stages.s1.b1.block.0.0.weight: grad mean = nan
model.stages.s1.b1.block.0.1.weight: grad mean = nan
model.stages.s1.b1.block.0.1.bias: grad mean = nan
model.stages.s1.b1.block.1.0.weight: grad mean = nan
model.stages.s1.b1.block.1.1.weight: grad mean = nan
model.stages.s1.b1.block.1.1.bias: grad mean = nan
model.stages.s1.b1.block.2.0.weight: grad mean = nan
model.stages.s1.b1.block.2.1.weight: grad mean = nan
model.stages.s1.b1.block.2.1.bias: grad mean = nan
model.stages.s1.b2.block.0.0.weight: grad mean = nan
model.stages.s1.b2.block.0.1.weight: grad mean = nan
model.stages.s1.b2.block.0.1.bias: grad mean = nan
model.stages.s1.b2.block.1.0.weight: grad mean = nan
model.stages.s1.b2.block.1.1.weight: grad mean = nan
model.stages.s1.b2.block.1.1.bias: grad mean = nan
model.stages.s1.b2.block.2.0.weight: grad mean = nan
model.stages.s1.b2.block.2.1.weight: grad mean = nan
model.stages.s1.b2.block.2.1.bias: grad mean = nan
model.stages.s1.b3.block.0.0.weight: grad mean = nan
model.stages.s1.b3.block.0.1.weight: grad mean = nan
model.stages.s1.b3.block.0.1.bias: grad mean = nan
model.stages.s1.b3.block.1.0.weight: grad mean = nan
model.stages.s1.b3.block.1.1.weight: grad mean = nan
model.stages.s1.b3.block.1.1.bias: grad mean = nan
model.stages.s1.b3.block.2.0.weight: grad mean = nan
model.stages.s1.b3.block.2.1.weight: grad mean = nan
model.stages.s1.b3.block.2.1.bias: grad mean = nan
model.stages.s2.b4.block.0.0.weight: grad mean = nan
model.stages.s2.b4.block.0.1.weight: grad mean = nan
model.stages.s2.b4.block.0.1.bias: grad mean = nan
model.stages.s2.b4.block.1.0.weight: grad mean = nan
model.stages.s2.b4.block.1.1.weight: grad mean = nan
model.stages.s2.b4.block.1.1.bias: grad mean = nan
model.stages.s2.b4.block.2.0.weight: grad mean = nan
model.stages.s2.b4.block.2.1.weight: grad mean = nan
model.stages.s2.b4.block.2.1.bias: grad mean = nan
model.stages.s2.b5.block.0.0.weight: grad mean = nan
model.stages.s2.b5.block.0.1.weight: grad mean = nan
model.stages.s2.b5.block.0.1.bias: grad mean = nan
model.stages.s2.b5.block.1.0.weight: grad mean = nan
model.stages.s2.b5.block.1.1.weight: grad mean = nan
model.stages.s2.b5.block.1.1.bias: grad mean = nan
model.stages.s2.b5.block.2.0.weight: grad mean = nan
model.stages.s2.b5.block.2.1.weight: grad mean = nan
model.stages.s2.b5.block.2.1.bias: grad mean = nan
model.stages.s3.b6.block.0.0.weight: grad mean = nan
model.stages.s3.b6.block.0.1.weight: grad mean = nan
model.stages.s3.b6.block.0.1.bias: grad mean = nan
model.stages.s3.b6.block.1.0.weight: grad mean = nan
model.stages.s3.b6.block.1.1.weight: grad mean = nan
model.stages.s3.b6.block.1.1.bias: grad mean = nan
model.stages.s3.b6.block.2.0.weight: grad mean = nan
model.stages.s3.b6.block.2.1.weight: grad mean = nan
model.stages.s3.b6.block.2.1.bias: grad mean = nan
model.feature_extractor.0.weight: grad mean = nan
model.feature_extractor.1.weight: grad mean = nan
model.feature_extractor.1.bias: grad mean = nan
model.device_embedding.weight: grad mean = nan
model.classifier.0.weight: grad mean = nan
model.classifier.0.bias: grad mean = nan
model.classifier.2.weight: grad mean = nan
model.classifier.2.bias: grad mean = nan
Epoch 6:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s, v_num=2]Loss is NaN! Check inputs and model outputs.
mel_spec stats: -11.512925148010254 10.666762351989746 -1.4655009508132935
y_hat stats: nan nan nan
Gradients after backward pass:
model.in_c.0.0.weight: grad mean = nan
model.in_c.0.1.weight: grad mean = nan
model.in_c.0.1.bias: grad mean = nan
model.in_c.1.0.weight: grad mean = nan
model.in_c.1.1.weight: grad mean = nan
model.in_c.1.1.bias: grad mean = nan
model.stages.s1.b1.block.0.0.weight: grad mean = nan
model.stages.s1.b1.block.0.1.weight: grad mean = nan
model.stages.s1.b1.block.0.1.bias: grad mean = nan
model.stages.s1.b1.block.1.0.weight: grad mean = nan
model.stages.s1.b1.block.1.1.weight: grad mean = nan
model.stages.s1.b1.block.1.1.bias: grad mean = nan
model.stages.s1.b1.block.2.0.weight: grad mean = nan
model.stages.s1.b1.block.2.1.weight: grad mean = nan
model.stages.s1.b1.block.2.1.bias: grad mean = nan
model.stages.s1.b2.block.0.0.weight: grad mean = nan
model.stages.s1.b2.block.0.1.weight: grad mean = nan
model.stages.s1.b2.block.0.1.bias: grad mean = nan
model.stages.s1.b2.block.1.0.weight: grad mean = nan
model.stages.s1.b2.block.1.1.weight: grad mean = nan
model.stages.s1.b2.block.1.1.bias: grad mean = nan
model.stages.s1.b2.block.2.0.weight: grad mean = nan
model.stages.s1.b2.block.2.1.weight: grad mean = nan
model.stages.s1.b2.block.2.1.bias: grad mean = nan
model.stages.s1.b3.block.0.0.weight: grad mean = nan
model.stages.s1.b3.block.0.1.weight: grad mean = nan
model.stages.s1.b3.block.0.1.bias: grad mean = nan
model.stages.s1.b3.block.1.0.weight: grad mean = nan
model.stages.s1.b3.block.1.1.weight: grad mean = nan
model.stages.s1.b3.block.1.1.bias: grad mean = nan
model.stages.s1.b3.block.2.0.weight: grad mean = nan
model.stages.s1.b3.block.2.1.weight: grad mean = nan
model.stages.s1.b3.block.2.1.bias: grad mean = nan
model.stages.s2.b4.block.0.0.weight: grad mean = nan
model.stages.s2.b4.block.0.1.weight: grad mean = nan
model.stages.s2.b4.block.0.1.bias: grad mean = nan
model.stages.s2.b4.block.1.0.weight: grad mean = nan
model.stages.s2.b4.block.1.1.weight: grad mean = nan
model.stages.s2.b4.block.1.1.bias: grad mean = nan
model.stages.s2.b4.block.2.0.weight: grad mean = nan
model.stages.s2.b4.block.2.1.weight: grad mean = nan
model.stages.s2.b4.block.2.1.bias: grad mean = nan
model.stages.s2.b5.block.0.0.weight: grad mean = nan
model.stages.s2.b5.block.0.1.weight: grad mean = nan
model.stages.s2.b5.block.0.1.bias: grad mean = nan
model.stages.s2.b5.block.1.0.weight: grad mean = nan
model.stages.s2.b5.block.1.1.weight: grad mean = nan
model.stages.s2.b5.block.1.1.bias: grad mean = nan
model.stages.s2.b5.block.2.0.weight: grad mean = nan
model.stages.s2.b5.block.2.1.weight: grad mean = nan
model.stages.s2.b5.block.2.1.bias: grad mean = nan
model.stages.s3.b6.block.0.0.weight: grad mean = nan
model.stages.s3.b6.block.0.1.weight: grad mean = nan
model.stages.s3.b6.block.0.1.bias: grad mean = nan
model.stages.s3.b6.block.1.0.weight: grad mean = nan
model.stages.s3.b6.block.1.1.weight: grad mean = nan
model.stages.s3.b6.block.1.1.bias: grad mean = nan
model.stages.s3.b6.block.2.0.weight: grad mean = nan
model.stages.s3.b6.block.2.1.weight: grad mean = nan
model.stages.s3.b6.block.2.1.bias: grad mean = nan
model.feature_extractor.0.weight: grad mean = nan
model.feature_extractor.1.weight: grad mean = nan
model.feature_extractor.1.bias: grad mean = nan
model.device_embedding.weight: grad mean = nan
model.classifier.0.weight: grad mean = nan
model.classifier.0.bias: grad mean = nan
model.classifier.2.weight: grad mean = nan
model.classifier.2.bias: grad mean = nan
Epoch 7:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s, v_num=2]Loss is NaN! Check inputs and model outputs.
mel_spec stats: -11.512925148010254 10.601778030395508 -1.3847918510437012
y_hat stats: nan nan nan
Gradients after backward pass:
`Trainer.fit` stopped: `max_epochs=10` reached.
C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\pytorch_lightning\trainer\connectors\checkpoint_connector.py:186: .test(ckpt_path="last") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
C:\Users\fenel\anaconda3\envs\d24_t1\lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.
model.in_c.0.0.weight: grad mean = nan
model.in_c.0.1.weight: grad mean = nan
model.in_c.0.1.bias: grad mean = nan
model.in_c.1.0.weight: grad mean = nan
model.in_c.1.1.weight: grad mean = nan
model.in_c.1.1.bias: grad mean = nan
model.stages.s1.b1.block.0.0.weight: grad mean = nan
model.stages.s1.b1.block.0.1.weight: grad mean = nan
model.stages.s1.b1.block.0.1.bias: grad mean = nan
model.stages.s1.b1.block.1.0.weight: grad mean = nan
model.stages.s1.b1.block.1.1.weight: grad mean = nan
model.stages.s1.b1.block.1.1.bias: grad mean = nan
model.stages.s1.b1.block.2.0.weight: grad mean = nan
model.stages.s1.b1.block.2.1.weight: grad mean = nan
model.stages.s1.b1.block.2.1.bias: grad mean = nan
model.stages.s1.b2.block.0.0.weight: grad mean = nan
model.stages.s1.b2.block.0.1.weight: grad mean = nan
model.stages.s1.b2.block.0.1.bias: grad mean = nan
model.stages.s1.b2.block.1.0.weight: grad mean = nan
model.stages.s1.b2.block.1.1.weight: grad mean = nan
model.stages.s1.b2.block.1.1.bias: grad mean = nan
model.stages.s1.b2.block.2.0.weight: grad mean = nan
model.stages.s1.b2.block.2.1.weight: grad mean = nan
model.stages.s1.b2.block.2.1.bias: grad mean = nan
model.stages.s1.b3.block.0.0.weight: grad mean = nan
model.stages.s1.b3.block.0.1.weight: grad mean = nan
model.stages.s1.b3.block.0.1.bias: grad mean = nan
model.stages.s1.b3.block.1.0.weight: grad mean = nan
model.stages.s1.b3.block.1.1.weight: grad mean = nan
model.stages.s1.b3.block.1.1.bias: grad mean = nan
model.stages.s1.b3.block.2.0.weight: grad mean = nan
model.stages.s1.b3.block.2.1.weight: grad mean = nan
model.stages.s1.b3.block.2.1.bias: grad mean = nan
model.stages.s2.b4.block.0.0.weight: grad mean = nan
model.stages.s2.b4.block.0.1.weight: grad mean = nan
model.stages.s2.b4.block.0.1.bias: grad mean = nan
model.stages.s2.b4.block.1.0.weight: grad mean = nan
model.stages.s2.b4.block.1.1.weight: grad mean = nan
model.stages.s2.b4.block.1.1.bias: grad mean = nan
model.stages.s2.b4.block.2.0.weight: grad mean = nan
model.stages.s2.b4.block.2.1.weight: grad mean = nan
model.stages.s2.b4.block.2.1.bias: grad mean = nan
model.stages.s2.b5.block.0.0.weight: grad mean = nan
model.stages.s2.b5.block.0.1.weight: grad mean = nan
model.stages.s2.b5.block.0.1.bias: grad mean = nan
model.stages.s2.b5.block.1.0.weight: grad mean = nan
model.stages.s2.b5.block.1.1.weight: grad mean = nan
model.stages.s2.b5.block.1.1.bias: grad mean = nan
model.stages.s2.b5.block.2.0.weight: grad mean = nan
model.stages.s2.b5.block.2.1.weight: grad mean = nan
model.stages.s2.b5.block.2.1.bias: grad mean = nan
model.stages.s3.b6.block.0.0.weight: grad mean = nan
model.stages.s3.b6.block.0.1.weight: grad mean = nan
model.stages.s3.b6.block.0.1.bias: grad mean = nan
model.stages.s3.b6.block.1.0.weight: grad mean = nan
model.stages.s3.b6.block.1.1.weight: grad mean = nan
model.stages.s3.b6.block.1.1.bias: grad mean = nan
model.stages.s3.b6.block.2.0.weight: grad mean = nan
model.stages.s3.b6.block.2.1.weight: grad mean = nan
model.stages.s3.b6.block.2.1.bias: grad mean = nan
model.feature_extractor.0.weight: grad mean = nan
model.feature_extractor.1.weight: grad mean = nan
model.feature_extractor.1.bias: grad mean = nan
model.device_embedding.weight: grad mean = nan
model.classifier.0.weight: grad mean = nan
model.classifier.0.bias: grad mean = nan
model.classifier.2.weight: grad mean = nan
model.classifier.2.bias: grad mean = nan
Epoch 8:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s, v_num=2]NaN detected before log in mel_forward
NaN detected after log in mel_forward
Loss is NaN! Check inputs and model outputs.
NaN detected before log in mel_forward
NaN detected after log in mel_forward
mel_spec stats: nan nan nan
y_hat stats: nan nan nan
Gradients after backward pass:
model.in_c.0.0.weight: grad mean = nan
model.in_c.0.1.weight: grad mean = nan
model.in_c.0.1.bias: grad mean = nan
model.in_c.1.0.weight: grad mean = nan
model.in_c.1.1.weight: grad mean = nan
model.in_c.1.1.bias: grad mean = nan
model.stages.s1.b1.block.0.0.weight: grad mean = nan
model.stages.s1.b1.block.0.1.weight: grad mean = nan
model.stages.s1.b1.block.0.1.bias: grad mean = nan
model.stages.s1.b1.block.1.0.weight: grad mean = nan
model.stages.s1.b1.block.1.1.weight: grad mean = nan
model.stages.s1.b1.block.1.1.bias: grad mean = nan
model.stages.s1.b1.block.2.0.weight: grad mean = nan
model.stages.s1.b1.block.2.1.weight: grad mean = nan
model.stages.s1.b1.block.2.1.bias: grad mean = nan
model.stages.s1.b2.block.0.0.weight: grad mean = nan
model.stages.s1.b2.block.0.1.weight: grad mean = nan
model.stages.s1.b2.block.0.1.bias: grad mean = nan
model.stages.s1.b2.block.1.0.weight: grad mean = nan
model.stages.s1.b2.block.1.1.weight: grad mean = nan
model.stages.s1.b2.block.1.1.bias: grad mean = nan
model.stages.s1.b2.block.2.0.weight: grad mean = nan
model.stages.s1.b2.block.2.1.weight: grad mean = nan
model.stages.s1.b2.block.2.1.bias: grad mean = nan
model.stages.s1.b3.block.0.0.weight: grad mean = nan
model.stages.s1.b3.block.0.1.weight: grad mean = nan
model.stages.s1.b3.block.0.1.bias: grad mean = nan
model.stages.s1.b3.block.1.0.weight: grad mean = nan
model.stages.s1.b3.block.1.1.weight: grad mean = nan
model.stages.s1.b3.block.1.1.bias: grad mean = nan
model.stages.s1.b3.block.2.0.weight: grad mean = nan
model.stages.s1.b3.block.2.1.weight: grad mean = nan
model.stages.s1.b3.block.2.1.bias: grad mean = nan
model.stages.s2.b4.block.0.0.weight: grad mean = nan
model.stages.s2.b4.block.0.1.weight: grad mean = nan
model.stages.s2.b4.block.0.1.bias: grad mean = nan
model.stages.s2.b4.block.1.0.weight: grad mean = nan
model.stages.s2.b4.block.1.1.weight: grad mean = nan
model.stages.s2.b4.block.1.1.bias: grad mean = nan
model.stages.s2.b4.block.2.0.weight: grad mean = nan
model.stages.s2.b4.block.2.1.weight: grad mean = nan
model.stages.s2.b4.block.2.1.bias: grad mean = nan
model.stages.s2.b5.block.0.0.weight: grad mean = nan
model.stages.s2.b5.block.0.1.weight: grad mean = nan
model.stages.s2.b5.block.0.1.bias: grad mean = nan
model.stages.s2.b5.block.1.0.weight: grad mean = nan
model.stages.s2.b5.block.1.1.weight: grad mean = nan
model.stages.s2.b5.block.1.1.bias: grad mean = nan
model.stages.s2.b5.block.2.0.weight: grad mean = nan
model.stages.s2.b5.block.2.1.weight: grad mean = nan
model.stages.s2.b5.block.2.1.bias: grad mean = nan
model.stages.s3.b6.block.0.0.weight: grad mean = nan
model.stages.s3.b6.block.0.1.weight: grad mean = nan
model.stages.s3.b6.block.0.1.bias: grad mean = nan
model.stages.s3.b6.block.1.0.weight: grad mean = nan
model.stages.s3.b6.block.1.1.weight: grad mean = nan
model.stages.s3.b6.block.1.1.bias: grad mean = nan
model.stages.s3.b6.block.2.0.weight: grad mean = nan
model.stages.s3.b6.block.2.1.weight: grad mean = nan
model.stages.s3.b6.block.2.1.bias: grad mean = nan
model.feature_extractor.0.weight: grad mean = nan
model.feature_extractor.1.weight: grad mean = nan
model.feature_extractor.1.bias: grad mean = nan
model.device_embedding.weight: grad mean = nan
model.classifier.0.weight: grad mean = nan
model.classifier.0.bias: grad mean = nan
model.classifier.2.weight: grad mean = nan
model.classifier.2.bias: grad mean = nan
Epoch 9:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s, v_num=2]Loss is NaN! Check inputs and model outputs.
mel_spec stats: -11.512925148010254 10.96739387512207 -1.4737107753753662
y_hat stats: nan nan nan
Gradients after backward pass:
model.in_c.0.0.weight: grad mean = nan
model.in_c.0.1.weight: grad mean = nan
model.in_c.0.1.bias: grad mean = nan
model.in_c.1.0.weight: grad mean = nan
model.in_c.1.1.weight: grad mean = nan
model.in_c.1.1.bias: grad mean = nan
model.stages.s1.b1.block.0.0.weight: grad mean = nan
model.stages.s1.b1.block.0.1.weight: grad mean = nan
model.stages.s1.b1.block.0.1.bias: grad mean = nan
model.stages.s1.b1.block.1.0.weight: grad mean = nan
model.stages.s1.b1.block.1.1.weight: grad mean = nan
model.stages.s1.b1.block.1.1.bias: grad mean = nan
model.stages.s1.b1.block.2.0.weight: grad mean = nan
model.stages.s1.b1.block.2.1.weight: grad mean = nan
model.stages.s1.b1.block.2.1.bias: grad mean = nan
model.stages.s1.b2.block.0.0.weight: grad mean = nan
model.stages.s1.b2.block.0.1.weight: grad mean = nan
model.stages.s1.b2.block.0.1.bias: grad mean = nan
model.stages.s1.b2.block.1.0.weight: grad mean = nan
model.stages.s1.b2.block.1.1.weight: grad mean = nan
model.stages.s1.b2.block.1.1.bias: grad mean = nan
model.stages.s1.b2.block.2.0.weight: grad mean = nan
model.stages.s1.b2.block.2.1.weight: grad mean = nan
model.stages.s1.b2.block.2.1.bias: grad mean = nan
model.stages.s1.b3.block.0.0.weight: grad mean = nan
model.stages.s1.b3.block.0.1.weight: grad mean = nan
model.stages.s1.b3.block.0.1.bias: grad mean = nan
model.stages.s1.b3.block.1.0.weight: grad mean = nan
model.stages.s1.b3.block.1.1.weight: grad mean = nan
model.stages.s1.b3.block.1.1.bias: grad mean = nan
model.stages.s1.b3.block.2.0.weight: grad mean = nan
model.stages.s1.b3.block.2.1.weight: grad mean = nan
model.stages.s1.b3.block.2.1.bias: grad mean = nan
model.stages.s2.b4.block.0.0.weight: grad mean = nan
model.stages.s2.b4.block.0.1.weight: grad mean = nan
model.stages.s2.b4.block.0.1.bias: grad mean = nan
model.stages.s2.b4.block.1.0.weight: grad mean = nan
model.stages.s2.b4.block.1.1.weight: grad mean = nan
model.stages.s2.b4.block.1.1.bias: grad mean = nan
model.stages.s2.b4.block.2.0.weight: grad mean = nan
model.stages.s2.b4.block.2.1.weight: grad mean = nan
model.stages.s2.b4.block.2.1.bias: grad mean = nan
model.stages.s2.b5.block.0.0.weight: grad mean = nan
model.stages.s2.b5.block.0.1.weight: grad mean = nan
model.stages.s2.b5.block.0.1.bias: grad mean = nan
model.stages.s2.b5.block.1.0.weight: grad mean = nan
model.stages.s2.b5.block.1.1.weight: grad mean = nan
model.stages.s2.b5.block.1.1.bias: grad mean = nan
model.stages.s2.b5.block.2.0.weight: grad mean = nan
model.stages.s2.b5.block.2.1.weight: grad mean = nan
model.stages.s2.b5.block.2.1.bias: grad mean = nan
model.stages.s3.b6.block.0.0.weight: grad mean = nan
model.stages.s3.b6.block.0.1.weight: grad mean = nan
model.stages.s3.b6.block.0.1.bias: grad mean = nan
model.stages.s3.b6.block.1.0.weight: grad mean = nan
model.stages.s3.b6.block.1.1.weight: grad mean = nan
model.stages.s3.b6.block.1.1.bias: grad mean = nan
model.stages.s3.b6.block.2.0.weight: grad mean = nan
model.stages.s3.b6.block.2.1.weight: grad mean = nan
model.stages.s3.b6.block.2.1.bias: grad mean = nan
model.feature_extractor.0.weight: grad mean = nan
model.feature_extractor.1.weight: grad mean = nan
model.feature_extractor.1.bias: grad mean = nan
model.device_embedding.weight: grad mean = nan
model.classifier.0.weight: grad mean = nan
model.classifier.0.bias: grad mean = nan
model.classifier.2.weight: grad mean = nan
model.classifier.2.bias: grad mean = nan
Epoch 9: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.72it/s, v_num=2]





































































































Testing DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 116/116 [03:35<00:00,  0.54it/s]Test epoch ended; computing metrics...
Testing DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 116/116 [03:35<00:00,  0.54it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        Test metric               DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
         test/acc              0.0997304618358612
        test/acc.a             0.10000000149011612
     test/acc.airport                  1.0
        test/acc.b             0.09726443886756897
       test/acc.bus                    0.0
        test/acc.c             0.10030394792556763
      test/acc.metro                   0.0
  test/acc.metro_station               0.0
       test/acc.park                   0.0
  test/acc.public_square               0.0
       test/acc.real           0.09919027984142303
        test/acc.s1            0.10000000149011612
        test/acc.s2            0.10000000149011612
        test/acc.s3            0.10000000149011612
        test/acc.s4            0.10000000149011612
        test/acc.s5            0.10000000149011612
        test/acc.s6            0.10000000149011612
       test/acc.seen           0.10000000149011612
  test/acc.shopping_mall               0.0
test/acc.street_pedestrian             0.0
  test/acc.street_traffic              0.0
       test/acc.tram                   0.0
      test/acc.unseen          0.10000000149011612
        test/cnt.a                   3300.0
     test/cnt.airport                2960.0
        test/cnt.b                   3290.0
       test/cnt.bus                  2970.0
        test/cnt.c                   3290.0
      test/cnt.metro                 2970.0
  test/cnt.metro_station             2970.0
       test/cnt.park                 2970.0
  test/cnt.public_square             2970.0
        test/cnt.s1                  3300.0
        test/cnt.s2                  3300.0
        test/cnt.s3                  3300.0
        test/cnt.s4                  3300.0
        test/cnt.s5                  3300.0
        test/cnt.s6                  3300.0
  test/cnt.shopping_mall             2970.0
test/cnt.street_pedestrian           2970.0
  test/cnt.street_traffic            2970.0
       test/cnt.tram                 2960.0
      test/count.real                9880.0
      test/count.seen                9900.0
     test/count.unseen               9900.0
      test/lloss.real                  nan
      test/lloss.seen                  nan
     test/lloss.unseen                 nan
         test/loss                     nan
        test/loss.a                    nan
     test/loss.airport                 nan
        test/loss.b                    nan
       test/loss.bus                   nan
        test/loss.c                    nan
      test/loss.metro                  nan
  test/loss.metro_station              nan
      test/loss.park                   nan
  test/loss.public_square              nan
       test/loss.s1                    nan
       test/loss.s2                    nan
       test/loss.s3                    nan
       test/loss.s4                    nan
       test/loss.s5                    nan
       test/loss.s6                    nan
  test/loss.shopping_mall              nan
test/loss.street_pedestrian            nan
 test/loss.street_traffic              nan
      test/loss.tram                   nan
    test/macro_avg_acc         0.10000000149011612
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────